{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <center>Introduction to Parallel R</center>\n",
    "<p>\n",
    "<center>Robert Bjornson</center> \n",
    "<p>\n",
    "<center><i>Yale Center for Research Computing</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Yale Center for Research Computing?\n",
    "\n",
    "\n",
    "- Independent center under the Provost's office\n",
    "- Created to support your research computing needs\n",
    "- Focus is on high performance computing and storage\n",
    "- ~20 staff, including applications specialists and system engineers\n",
    "- Available to consult with and educate users\n",
    "- Manage compute clusters and support users\n",
    "- Located at 160 St. Ronan st, at the corner of Edwards and St. Ronan\n",
    "- http://research.computing.yale.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial materials\n",
    "On our github: ``` git clone git@github.com:ycrc/ParallelR.git ```\n",
    "\n",
    "or download ```https://github.com/ycrc/ParallelR.git```\n",
    "\n",
    "The presentation is a jupyter notebook.  A static copy is available here:\n",
    "https://github.com/ycrc/ParallelR/blob/master/ParallelR.ipynb\n",
    "\n",
    "Code examples are in Examples/Presentation\n",
    "\n",
    "To run the code (either files or jupyter) you'll need to install the R packages as described below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Presentation\n",
    "- Intro to Parallel R\n",
    "- Using Foreach for parallelism in R\n",
    "- Examples using Foreach \n",
    "- Other options\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does \"Parallel R\" mean?\n",
    "In increasing level of complexity:\n",
    "\n",
    "1. Lots of independent, sequential R jobs that could be run in parallel\n",
    "1. An R program containing a \"loop\" with completely independent iterations\n",
    "1. An R program with a decomposition involving communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing your own Parallel R environment \n",
    "\n",
    "We recommend using conda\n",
    "\n",
    "```\n",
    "$ module load miniconda\n",
    "$ conda create --name parallel_r -c conda-forge r-base r-essentials r-doMC r-Rmpi\n",
    "```\n",
    "\n",
    "This final step (only necessary for the doMPI backend) must be done on login node.\n",
    "```\n",
    "$ R\n",
    "> install.packages('doMPI')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel R Packages\n",
    "\n",
    "\n",
    "- Parallel apply approaches:\n",
    " - snow: original multihost, tcp/ssh method \n",
    " - multicore: original forking method\n",
    " - parallel: unification of multicore and snow\n",
    "- Foreach: high level, parallel for loop method\n",
    "- Rmpi: interface to MPI for advanced parallel programming\n",
    "\n",
    "_Parallel R_ by Stephen Weston, O'Reilly Press (unfortunately predates foreach)\n",
    "\n",
    "We will focus on __foreach__:\n",
    "- easy to use\n",
    "- more general than parallel apply "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foreach\n",
    "- designed and implemented by Steve Weston\n",
    "- natural semantics, similar to _for_ loop\n",
    "- [documentation](https://www.rdocumentation.org/packages/foreach/versions/1.4.7/topics/foreach)\n",
    "- [vignette](https://cran.r-project.org/web/packages/foreach/vignettes/foreach.pdf)\n",
    "- works on multiple cpus on one machine, or on many machines\n",
    "\n",
    "Foreach iterates over 1 or more indices, executes an expression on those indices, and returns a collection, by default a list:\n",
    "```\n",
    "l <- foreach (arguments ...) %dopar% expr\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foreach\n",
    "- Foreach code is independent of parallel \"backend\"\n",
    "- Code registers a backend\n",
    "- Variety of available backends\n",
    " - doMC (only linux and macos)\n",
    " - doSNOW\n",
    " - doParallel (also works on windows)\n",
    " - doMPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setup for \"forked\" parallelism\n",
    "\n",
    "library(foreach)\n",
    "library(doMC)\n",
    "registerDoMC(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res <- foreach(i=1:8) %dopar% {\n",
    "    i*i\n",
    "}\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# simple function that simulates computing for set time\n",
    "spin<-function(sec) {\n",
    "\n",
    "  start<-proc.time()[[3]]\n",
    "\n",
    "  while (TRUE) {\n",
    "    z=1;\n",
    "    for (i in 1:100000) {\n",
    "      z<-z+1\n",
    "    }\n",
    "    now<-proc.time()[[3]]\n",
    "    if (now-start > sec) { break }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spin(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f<-function(i){\n",
    "    spin(i)\n",
    "    i*i\n",
    "}\n",
    "\n",
    "system.time({\n",
    "res<-foreach (i=1:8) %dopar% \n",
    "{\n",
    "   f(i)\n",
    "}\n",
    "})\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rather than use a function, we can just put code in the block directly\n",
    "# foreach will return the value of the last expression\n",
    "res<-foreach (i=1:8) %dopar% \n",
    "{\n",
    "    spin(i)\n",
    "    i*i\n",
    "}\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combiners\n",
    "Rather than returning the raw list, we can combine (reduce) the values.  Foreach supports many combiners, using the named parameter .combine:\n",
    " - \"c\", \"+\", \"*\", \"cbind\", \"rbind\"\n",
    " - arbitrary user-supplied function of two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here, we add all of the results into a single integer\n",
    "res<-foreach (i=1:8, .combine=\"+\") %dopar% \n",
    "{\n",
    "    spin(i)\n",
    "    i*i\n",
    "}\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that we got the right answer\n",
    "sum(1:8 * 1:8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mymax <- function(a,b) {\n",
    "    if (a>b) a else b\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# User supplied combiner function.  \n",
    "# Note: you can also use .combine=\"mymax\"\n",
    "res<-foreach (i=1:8, .combine=mymax) %dopar% \n",
    "{\n",
    "    spin(i)\n",
    "    i*i\n",
    "}\n",
    "\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Be very careful not to forget the dot!\n",
    "# Here, combine is an iteration variable with only 1 value\n",
    "# So, we only use 1 value from i, and iterate once!\n",
    "\n",
    "res<-foreach (i=1:10, combine=\"+\") %dopar% \n",
    "{\n",
    "    spin(i)\n",
    "    i*i\n",
    "}\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Indices and Nested Foreach's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how to iterate over multiple indices\n",
    "system.time(\n",
    "  res<-foreach (i=1:3, j=10:12) %dopar%\n",
    "  {  \n",
    "    spin(i)\n",
    "    i*j\n",
    "  }\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful, foreach will iterate over the shortest sequence!\n",
    "# This was the problem with combine=\"+\", above!\n",
    "system.time(\n",
    "  res<-foreach (i=1:4, j=10:12) %dopar%\n",
    "  {  \n",
    "    spin(i)\n",
    "    i*j\n",
    "  }\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how to nest foreach's using %:%\n",
    "# result is a list of lists\n",
    "system.time(\n",
    "  res<-foreach (i=1:3) %:% \n",
    "  foreach (j=1:4) %dopar% {\n",
    "    i*j\n",
    "  }\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By clever use of combiners, we can arrange to get a matrix back\n",
    "system.time(\n",
    "  res<-foreach (i=1:3, .combine='cbind') %:% \n",
    "  foreach (j=1:4, .combine='c') %dopar% {\n",
    "    i*j\n",
    "  }\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving beyond the jupyter notebook\n",
    "- So far, I've been using the cpus my jupyter notebook has allocated\n",
    "- How do I run parallel R codes on the cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating foreach+doMC with Slurm\n",
    "- Using slurm, request desired cores using -c\n",
    "- In R code, query slurm env variable to get core count for registration:\n",
    "```\n",
    "cores<-strtoi(Sys.getenv('SLURM_CPUS_PER_TASK', unset=1))\n",
    "registerDoMC(cores)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example batch script using foreach and doMC\n",
    "```\n",
    "#!/bin/bash\n",
    "#SBATCH -c 4 \n",
    "\n",
    "module load miniconda\n",
    "source activate parallel_r\n",
    "R --slave -f ex1.R\n",
    "```\n",
    "\n",
    "Example scripts:  Examples/foreach/ex1.sh and ex1.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterators library\n",
    "- Since foreach likes to iterate over things, the _iterators_ library can be very useful\n",
    "\n",
    "https://cran.r-project.org/web/packages/iterators/vignettes/iterators.pdf\n",
    "\n",
    "```\n",
    "icount(n)  # iterates n times\n",
    "iter(func) # wraps func with iterator\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreach(icount(1000), .combine='+') %do% 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifun <- iter(function() sample(0:9, 4, replace=TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nextElem(ifun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more complex use of iterators\n",
    "foreach(icount(10), v=iter(function() sample(0:9, 4, replace=TRUE))) %do%\n",
    "    v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using multiple machines/nodes\n",
    "- Thus far, we've only used multiple cpus on a single node, via doMC\n",
    "- Advantages:\n",
    " - Very simple to use\n",
    " - Environment automatically inherited\n",
    "- But:\n",
    " - Limits the degree of parallelism to cpus on one node (e.g. 28)\n",
    "- Using the MPI \"backend\" allows us to scale to 100s or 1000s of cpus\n",
    "- (Almost) no change required to code body. We just create and register a different backend \n",
    "- Make sure to clean up at end:\n",
    "```\n",
    "closeCluster(cl)\n",
    "mpi.quit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes to R code to use MPI backend\n",
    "replace\n",
    "```\n",
    "library(doMC)\n",
    "registerDoMC(cores)\n",
    "```\n",
    "with\n",
    "```\n",
    "library(doMPI)\n",
    "cl<-startMPIcluster(verbose=TRUE, logdir=\"log\")\n",
    "registerDoMPI(cl)\n",
    "...\n",
    "\n",
    "closeCluster(cl)\n",
    "mpi.quit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doMPI Foreach batch script\n",
    "```\n",
    "#!/bin/bash\n",
    "#SBATCH -n 4 -N 4\n",
    "\n",
    "module load miniconda\n",
    "source activate parallel_r\n",
    "mpirun R --slave -f ex1mpi.R\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on using multiple nodes\n",
    "- It is possible to use other backends (doParallel or doSnow) to run on multiple nodes.  On our HPC clusters, we recommend doMPI+slurm\n",
    "- It is possible to specify the number of workers: ```startMPIcluster(count=3)``` but best to let slurm handle it\n",
    "- The number of workers is slurm ntasks-1\n",
    "- DON'T query SLURM_NTASKS; only the master sees the right value (???)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on using random numbers with Foreach\n",
    "- Each worker is a separate process with its own random number stream.  \n",
    "- Setting seed in the master won't make results reproduceable\n",
    "- To make results reproduceable, set seed inside foreach loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We get different results each time, despite setting seed\n",
    "library(foreach)\n",
    "library(doMC)\n",
    "\n",
    "registerDoMC(4) \n",
    "set.seed(1)\n",
    "r <- foreach(i = 1:5, .combine = \"c\") %dopar% {\n",
    "    rnorm(1)\n",
    "}\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now our results are reproduceable\n",
    "library(foreach)\n",
    "library(doMC)\n",
    "\n",
    "registerDoMC(4) \n",
    "\n",
    "r <- foreach(i = 1:5, .combine = \"c\") %dopar% {\n",
    "    set.seed(i)\n",
    "    rnorm(1)\n",
    "}\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on foreach environment (Subtle but important!)\n",
    "\n",
    "The interations of foreach are done by \"workers\"\n",
    "\n",
    "The environment seen by the workers doing the interations of the foreach block differ between doMC and doMPI!\n",
    "\n",
    "- doMC is based on linux fork().  Workers get a full copy of the master environment, including libraries, variables, etc.\n",
    "- doMC starts fresh workers for every foreach.\n",
    "- in doMPI, the master and all workers execute the code up to the registerMPI().  The master continues on, but workers enter a worker loop there.  Thus, they have access only to things existing at that point, unless otherwise provided.\n",
    "- But, in addition, Foreach does its best to introspect the parallel code block, and provide needed variables.\n",
    "- You can explicitly provide packages using foreach's .packages\n",
    "- You can explicitly control export of variables using .export or .noexport\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Example\n",
    "Presentations/ex2.R and ex2mpi.R\n",
    "\n",
    "Illustrating:\n",
    "- use of .combine and .packages\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans\n",
    "- classic method for clustering data.  You supply the number of clusters; the algorithm creates clusters that minimize total distance\n",
    "\n",
    "```\n",
    "res<-kmeans(data, numclusters, reps)\n",
    "\n",
    "res$cluster       # cluster assignment for each datapoint\n",
    "res$tot.withinss  # measure of quality of clustering\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rides<-read.csv('Examples/Data/uber-raw-data-jun14.csv')\n",
    "head(rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs<-rides[,c('Lat','Lon')]\n",
    "head(locs)\n",
    "dim(locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res<-kmeans(locs,5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res$centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrs<-as.data.frame(res$centers)\n",
    "#ctrs<-rename(ctrs, c(\"Lon\"=\"x\", \"Lat\"=\"y\"))\n",
    "# get_googlemap really wants the df with lon, lat\n",
    "ctrs<-ctrs[,c(2,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages('ggmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(ggmap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "\n",
    "To make the following work, I had to:\n",
    "- enable maps static api and geocoding api on the google console for my project\n",
    "- get an api key (below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key<-trimws(readChar(\"/home/fas/lsprog/rdb9/Keys/gcpapikeys.txt\",nchars=1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_google(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ggmap(get_googlemap(center=c(lon=-73.97723, lat=40.75273), markers = ctrs, zoom=10, scale = 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sys.getenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cores<-strtoi(Sys.getenv('SLURM_JOB_CPUS_PER_NODE', unset=1))\n",
    "\n",
    "print(cores)\n",
    "registerDoMC(cores)\n",
    "\n",
    "starts=80\n",
    "tasks=2*cores\n",
    "nstarts=rep(ceiling(starts/tasks), tasks)\n",
    "clusters=seq(10,15)\n",
    "\n",
    "print(c(\"tasks\", tasks, \"nstarts\", nstarts, \"clusters\", clusters))\n",
    "\n",
    "system.time({\n",
    "results <-\n",
    "  foreach (nstart=nstarts, seed=seeds) %:%\n",
    "    foreach (cluster=clusters) %dopar% {\n",
    "  kmeans(locs, cluster, nstart=nstart)\n",
    "}})\n",
    "\n",
    "results2 <- unlist(results, recursive=FALSE)\n",
    "i = sapply(results2, function(result) result$tot.withinss)\n",
    "result = results2[[]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which.min(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_ctrs=as.data.frame(result$centers)[,c(2,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggmap(get_googlemap(center=c(lon=-73.97723, lat=40.75273), markers = par_ctrs, zoom=10, scale = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatives to Foreach\n",
    "- As mentioned, Parallel, Snow, and Multicore are other packages for Parallel R\n",
    "- Parallel is a unification of snow and multicore\n",
    "- all three provide various forms of parallel apply function\n",
    "- The \"unification\" can be extremely confusing\n",
    "- Less support for providing environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example using forking via parallel package.  Also see ex3.R\n",
    "\n",
    "library(parallel)\n",
    "\n",
    "nstarts=20\n",
    "cores=4\n",
    "\n",
    "f<-function(i) {\n",
    "  spin(1)\n",
    "  i*i\n",
    "}\n",
    "\n",
    "system.time({\n",
    "results <- mclapply(1:nstarts, f, mc.cores=cores)\n",
    "})\n",
    "\n",
    "print(Reduce('+', results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rmpi\n",
    "- MPI is a standard for writing parallel programs\n",
    "- Supports direct passing of messages between processes and collective operations: barriers, broadcasts, etc.\n",
    "\n",
    "Rmpi supports all of that, plus a higher level \"master/worker\" model.  It is very complicated.\n",
    "I've searched for compelling example programs.  Best found so far: pipelined prime number generator\n",
    "http://heather.cs.ucdavis.edu/~matloff/158/Rmpi.pdf\n",
    "\n",
    "- My advice; stay away!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dSQ\n",
    "dSQ makes it easy to run large numbers of independent jobs on the cluster, including R jobs\n",
    "\n",
    "First, create file containing list of commands to run (jobs.txt). I usually do this via a mkjobs script.\n",
    "```\n",
    "Rscript mkjobs.R\n",
    "```\n",
    "output\n",
    "```\n",
    "module load R; Rscript ex4.R 1 2 100 \n",
    "module load R; Rscript ex4.R 2 3 100 \n",
    "...\n",
    "```\n",
    "Then, generate the batch script and submit the job:\n",
    "```\n",
    "module load dSQ\n",
    "dSQ --job-file jobs.txt --mem-10g -t 0-1\n",
    "Batch script generated. To submit your jobs, run:\n",
    " sbatch dsq-jobs-2019-08-22.sh\n",
    "sbatch dsq-jobs-2019-08-22.sh\n",
    "dSQAutopsy dsq-jobs-*.sh *_status.tsv \n",
    "```\n",
    "\n",
    "Each job generates a single .RData file.  We need a final script that finds the best output, like we did with foreach\n",
    "\n",
    "```\n",
    "Rscript comb.R\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dSQ versus Foreach\n",
    "- dSQ is more adaptive on the cluster.  It will use as many cpus as it can get, growing and shrinking dynamically.  It can also use scavenge partition\n",
    "- dSQ should use less memory, since no process will need to hold all results at one time.  \n",
    "- dSQ has a higher startup overhead per task\n",
    "- the main program used in the dSQ tasks is EXACTLY the sequential program\n",
    "- foreach is more concise, one program to write versus one program and several scripts.  Especially true if the parallelizable portion of the program is (textually) small."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
